---
title: Ollamaを使い、GraphAIのチュートリアル（Hello World）を無料で試す方法について
tags:
  - 入門
  - HelloWorld
  - ollama
  - GraphAI
  - AIAgent
private: false
updated_at: '2024-12-05T14:53:29+09:00'
id: 550bcfa6b012429890a9
organization_url_name: null
slide: false
ignorePublish: false
---
## はじめに

[GraphAI](https://github.com/receptron/graphai)は、データフローグラフを使って非同期プロセスをシンプルに定義できるツールです。  
GraphAIを試す際に以下チュートリアルがあるのですが、チュートリアルがOpenAIをすることを前提に記載されてるため、無料でチュートリアルができるよう[Ollama](https://ollama.com/)を使ったやり方を説明します。

- [GraphAI チュートリアル | GitHub](https://github.com/receptron/graphai/blob/main/docs/Tutorial.md)

## GraphAI チュートリアル（Ollamaバージョン）

### インストール方法

GraphAIを使うために、次の手順に従ってGraphAIクライアントをインストールしてください。

```bash
npm i -g @receptron/graphai_cli
```

次に、現在のディレクトリに OPENAI_API_KEY を含む .env ファイルを作成してください。

```bash:.env
OPENAI_API_KEY=sk-...
```

注）
実際にはこちらは使われないが、設定しないと以下のエラーが発生するためサンプルの通りのファイルを用意してください。

```
$ graphai hello.yaml 
<-- NodeId: llm, Agent: openAIAgent
{ namedInputs: { prompt: "Explain ML's transformer in 100 words." } }
OpenAIError: The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).
```

Ollamaのインストール方法については各種記事がありますので、そちらを参考にしてください。



### 実行方法

まずは、下記の内容を`hello.yaml`という名前のファイルに保存してください。

```yaml:hello.yaml
version: 0.5
nodes:
  llm:
    agent: openAIAgent
    params:
      model: llama3
      baseURL: http://127.0.0.1:11434/v1
    inputs:
      prompt: Explain ML's transformer in 100 words.
  output:
    agent: copyAgent
    params:
      namedKey: text
    console:
      after: true
    inputs:
      text: :llm.text
```

その後、yamlファイル（「hello.yaml」など）を準備し、次のように入力します。

```bash
graphai hello.yaml
```

### 実行結果

ターミナルに次のように表示されればOKです。  
なお実際に実行した環境（MacBook Pro 2.4GHzクワッドコア Intel Core i5）だと実行結果がでるまで30秒ほどかかりました。

```
$ graphai hello.yaml
The Transformer is a neural network architecture introduced in the paper "Attention Is All You Need" by Vaswani et al. in 2017. It's primarily designed for machine translation tasks, but has since been widely applied to other areas, such as text classification, question answering, and language modeling. The Transformer eliminates the need for recurrent or convolutional layers by relying solely on self-attention mechanisms to process input sequences. This is achieved through an encoder-decoder structure, where the encoder breaks down the input into a sequence of tokens, and the decoder generates the output based on these tokens' relationships.
{}
```

## まとめ

この記事では、GraphAIの基本的なチュートリアルをOllamaを利用して無料で試す方法について解説しました。  

現在、メルマガ「週刊 Life is beautiful」が2025年で足かけ15年を迎えることを記念してアイデアソン・ハッカソンが進行中です。
この記事の内容を活用して、アイディアソン・ハッカソンに参加し、GraphAIを使ったアイデアやプロジェクトを開発して盛り上げていけたら嬉しいです。

https://github.com/snakajima/life-is-beautiful
